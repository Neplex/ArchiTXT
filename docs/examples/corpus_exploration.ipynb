{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b02239d8fef12638",
      "metadata": {},
      "source": [
        "Exploring a Textual Corpus with ArchiTXT\n",
        "========================================\n",
        "\n",
        "This tutorial provides a **step-by-step guide** on how to use **ArchiTXT** to efficiently process and analyze textual corpora.\n",
        "\n",
        "ArchiTXT allows loading a corpus as a set of syntax trees, where each tree is enriched by incorporating named entities.\n",
        "These enriched trees form a **forest**, which can then be automatically structured into a valid **database instance** for further analysis.\n",
        "\n",
        "By following this tutorial, you'll learn how to:\n",
        "- Load a corpus\n",
        "- Parse textual data with **Berkeley Neural Parser (Benepar)**\n",
        "- Extract structured data using **ArchiTXT**"
      ]
    },
    {
      "metadata": {
        "tags": [
          "remove-cell"
        ]
      },
      "cell_type": "code",
      "source": "!pip install git+https://github.com/Neplex/ArchiTXT.git#egg=architxt",
      "id": "c63d3027d162aa07",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "tags": [
          "remove-cell"
        ]
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "import itables\n",
        "\n",
        "itables.init_notebook_mode()"
      ],
      "id": "4a3490d7b8b0c24a"
    },
    {
      "cell_type": "markdown",
      "id": "115e771cc1456e16",
      "metadata": {},
      "source": [
        "## Downloading the MACCROBAT Corpus\n",
        "The **MACCROBAT** corpus is a collection of **200 annotated medical documents**, specifically **clinical case reports**, extracted from **PubMed Central**.\n",
        "The annotations focus on key medical concepts such as **diseases, treatments, medications, and symptoms**, making it a valuable resource for biomedical text analysis.\n",
        "\n",
        "The **MACCROBAT** corpus is available for download at [Figshare](https://figshare.com/articles/dataset/MACCROBAT2018/9764942).\n",
        "\n",
        "Let's download the corpora."
      ]
    },
    {
      "cell_type": "code",
      "id": "9bb17adb4e73b73",
      "metadata": {},
      "source": [
        "import io\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "with urllib.request.urlopen('https://figshare.com/ndownloader/articles/9764942/versions/2') as response:\n",
        "    archive_file = io.BytesIO(response.read())\n",
        "\n",
        "with zipfile.ZipFile(archive_file) as archive:\n",
        "    archive.extract('MACCROBAT2020.zip')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "f53f334f1db883be",
      "metadata": {},
      "source": [
        "## Installing and Configuring NLP Models\n",
        "\n",
        "ArchiTXT can parse the sentences using either **Benepar** with SpaCy or a **CoreNLP** server.\n",
        "In this tutorial, we will use the **SpaCy parser** with the default model, but you can use any models like one from **SciSpaCy**, a collection of models designed for biomedical text processing by **AllenAI**.\n",
        "\n",
        "To download the SciSpaCy model, do:"
      ]
    },
    {
      "cell_type": "code",
      "id": "f3f45627cd6a6589",
      "metadata": {
        "tags": [
          "remove-output"
        ]
      },
      "source": "!spacy download en_core_web_sm",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We also need to download the Benepar model for English",
      "id": "34644a1af9adac4d"
    },
    {
      "metadata": {
        "tags": [
          "remove-output"
        ]
      },
      "cell_type": "code",
      "source": [
        "import benepar\n",
        "\n",
        "benepar.download('benepar_en3')"
      ],
      "id": "97d57983410cd61",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "964d0fa93b704e92",
      "metadata": {},
      "source": [
        "## Parsing the Corpus with ArchiTXT\n",
        "\n",
        "Before processing the corpus, we need to configure the **BeneparParser**, specifying which SpaCy model to use for each language."
      ]
    },
    {
      "cell_type": "code",
      "id": "e14ee4fbe193af94",
      "metadata": {
        "tags": [
          "remove-output"
        ]
      },
      "source": [
        "import warnings\n",
        "\n",
        "from architxt.nlp.parser.benepar import BeneparParser\n",
        "\n",
        "# Initialize the parser\n",
        "parser = BeneparParser(\n",
        "    spacy_models={\n",
        "        'English': 'en_core_web_sm',\n",
        "    }\n",
        ")\n",
        "\n",
        "# Suppress warnings for unsupported annotations\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "d5e84953743102d3",
      "metadata": {},
      "source": "To ensure everything is working correctly, we first parse a small set of sentences from the corpus."
    },
    {
      "cell_type": "code",
      "id": "4c6432e9181b1433",
      "metadata": {
        "tags": [
          "remove-output"
        ]
      },
      "source": [
        "from architxt.nlp import raw_load_corpus\n",
        "\n",
        "forest = await raw_load_corpus(\n",
        "    ['MACCROBAT2020.zip'],\n",
        "    ['English'],\n",
        "    parser=parser,\n",
        "    sample=10,\n",
        "    cache=False,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "58d8649d5c7d04a9",
      "metadata": {},
      "source": "We can look at our enriched tree using the `pretty_print` method."
    },
    {
      "cell_type": "code",
      "id": "696fe1b6c3f4c838",
      "metadata": {},
      "source": [
        "# Look at the highest tree\n",
        "max(forest, key=lambda tree: tree.height()).pretty_print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "19ef99b0c8448f3a",
      "metadata": {},
      "source": [
        "Named Entity Resolution (NER) helps to standardize the named entities and to build a database instance.\n",
        "To enable NER, we need to provide the knowledge base to use.\n",
        "For this tutorial, we will use the **UMLS (Unified Medical Language System)** resolver.\n",
        "\n",
        "Let's now parse more sentences from the corpora."
      ]
    },
    {
      "cell_type": "code",
      "id": "dbc2309dbe83590f",
      "metadata": {
        "tags": [
          "remove-output"
        ]
      },
      "source": [
        "forest = await raw_load_corpus(\n",
        "    ['MACCROBAT2020.zip'],\n",
        "    ['English'],\n",
        "    parser=parser,\n",
        "    sample=800,\n",
        "    cache=False,\n",
        "    resolver_name='umls',\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": [
        "# Look at the highest tree\n",
        "max(forest, key=lambda tree: tree.height()).pretty_print()"
      ],
      "id": "b14bff3c8e7155ce",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "90088942bf499c9d",
      "metadata": {},
      "source": " **ArchiTXT** can then automatically structure parsed text into a **database-friendly format**."
    },
    {
      "metadata": {
        "tags": [
          "remove-output"
        ]
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "from architxt.simplification.tree_rewriting import rewrite\n",
        "\n",
        "new_forest = rewrite(forest, epoch=20, min_support=10, tau=0.8)"
      ],
      "id": "6eb636ebf75eba0d"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Look at the highest tree\n",
        "max(new_forest, key=lambda tree: tree.height()).pretty_print()"
      ],
      "id": "9f27bab9088de6ec"
    },
    {
      "cell_type": "markdown",
      "id": "2097e213eedb2081",
      "metadata": {},
      "source": [
        "Now that we have a structured instance, we can extract its schema.\n",
        "The schema provides a **formal representation** of the extracted data."
      ]
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": [
        "from architxt.schema import Schema\n",
        "\n",
        "schema = Schema.from_forest(new_forest, keep_unlabelled=False)\n",
        "print(schema.as_cfg())"
      ],
      "id": "d002e40e0ab4287d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Not all extracted trees contribute to meaningful insights.\n",
        "We can filter our structured instance to retain only **valid trees**:"
      ],
      "id": "b87a797643c215d8"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": "cleaned_forest = schema.extract_valid_trees(new_forest)",
      "id": "55d2846099d730ca",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Now that we have a structured dataset, we can explore the different **semantic groups**.\n",
        "Groups represent common patterns across the corpus."
      ],
      "id": "1e40371168773af1"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": [
        "datasets = schema.extract_datasets(new_forest)\n",
        "group = set(datasets.keys()).pop()\n",
        "\n",
        "datasets[group]"
      ],
      "id": "7ad51090714d6fbe",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
